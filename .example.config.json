{
    "api": {
        "host": "<IP_ADDRESS>",
        "port": "<PORT>"
    },
    "system": {
        "idle_timeout_sec": 300,
        "llama_server_path": "<LLAMA_SERVER_PATH>",
        "max_concurrent_models": 3,
        "request_timeout_sec": 300,
        "preload_models": [],
        "keep_warm_models": 2,
        "gpu_devices": [0],
        "parallel_requests": 4,
        "cpu_threads": 8,
        "use_mmap": true,
        "flash_attention": "on",
        "max_queue_size_per_model": 100,
        "queue_timeout_sec": 300
    },
    "models": {
        "<ALIAS_MODEL_1>": {
            "model_path": "<MODEL_PATH_1>",
            "params": {
                "n_gpu_layers": 99,
                "n_ctx": 4096,
                "embedding": false,
                "parallel_override": null,
                "batch_override": null
            }
        },
        "<ALIAS_MODEL_2>": {
            "model_path": "<MODEL_PATH_2>",
            "params": {
                "n_gpu_layers": 99,
                "n_ctx": 4096,
                "embedding": false,
                "parallel_override": null,
                "batch_override": null
            }
        },
        "<ALIAS_MODEL_EMBEDDING>": {
            "model_path": "<MODEL_PATH_EMBEDDINGS>",
            "params": {
                "n_gpu_layers": 99,
                "n_ctx": 4096,
                "embedding": true,
                "parallel_override": null,
                "batch_override": null
            }
        }
    }
}